{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Python is awesome.'\n",
    "words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ'), ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Python/NN is/VB awesome/JJ ./.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NN'), ('is', 'VB'), ('awesome', 'JJ'), ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ nltk.tag.str2tuple(word) for word in text.split() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged = brown.tagged_words()\n",
    "brown_tagged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NN'), ('is', 'NN'), ('awesome', 'NN'), ('.', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = 'Python is awesome.'\n",
    "words = nltk.word_tokenize(text)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = 'Python is awesome.'\n",
    "words = nltk.word_tokenize(text)\n",
    "defined_tags = {'is':'BEZ', 'over':'IN', 'who': 'WPS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', None), ('is', 'BEZ'), ('awesome', None), ('.', None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=defined_tags)\n",
    "baseline_tagger.tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='government')\n",
    "brown_sents = brown.sents(categories='government')\n",
    "len(brown_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2425"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(brown_sents)*0.8)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7799495586380832"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = brown_tagged_sents[:train_size]\n",
    "test_sents = brown_tagged_sents[train_size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('first', 'OD'),\n",
       " ('step', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('a', 'AT'),\n",
       " ('comprehensive', 'JJ'),\n",
       " ('self', None),\n",
       " ('study', 'NN'),\n",
       " ('made', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('faculty', None),\n",
       " (',', ','),\n",
       " ('by', 'IN'),\n",
       " ('outside', 'IN'),\n",
       " ('consultants', 'NNS'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('combination', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('two', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag(brown_sents[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the text corpus brown.\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Extract the list of tagged words from the corpus brown. Store the result in brown_tagged_words.\n",
    "brown_tagged_words     = [word for (word, tag) in nltk.corpus.brown.tagged_words()]\n",
    "\n",
    "# Generate trigrams of brown_tagged_words, and store the result in brown_tagged_trigrams.\n",
    "brown_tagged_trigrams  = list(nltk.trigrams(brown_tagged_words))\n",
    "\n",
    "# For every trigram of brown_tagged_trigrams, determine the tags associated with each word. This results in a list of tuples, \n",
    "# where each tuple contain pos tags of 3 consecutive words in text. Store the result in brown_trigram_pos_tags.\n",
    "brown_trigram_pos_tags = list()\n",
    "for trigram in brown_tagged_trigrams:\n",
    "    trigram_tagged = nltk.pos_tag(trigram)\n",
    "    tags = [tag for (word, tag) in trigram_tagged]\n",
    "    brown_trigram_pos_tags.append(tags)\n",
    "    \n",
    "# Determine the frequency distribution of brown_trigram_pos_tags, and store the result in brown_trigram_pos_tags_freq.\n",
    "\n",
    "# Print the number of occurrences of trigram ('JJ','NN','IN').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "brown_tagged_words     = [word for (word, tag) in nltk.corpus.brown.tagged_words()]\n",
    "brown_tagged_trigrams  = list(nltk.trigrams(brown_tagged_words))\n",
    "brown_trigram_pos_tags = list()\n",
    "for trigram in brown_tagged_trigrams:\n",
    "    trigram_tagged = nltk.pos_tag(trigram)\n",
    "    tags = [tag for (word, tag) in trigram_tagged]\n",
    "    brown_trigram_pos_tags.append(tags)\n",
    "\n",
    "brown_trigram_pos_tags_freq = nltk.FreqDist((t1,t2,t3) for (t1,t2,t3) in brown_trigram_pos_tags)\n",
    "print(brown_trigram_pos_tags_freq['JJ','NN','IN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_words = [w for w in brown.tagged_words()]\n",
    "brown_tagged_trigrams = nltk.trigrams(brown_tagged_words)\n",
    "\n",
    "brown_trigram_pos_tags = [(w1[1],w2[1],w3[1]) for w1,w2,w3 in brown_tagged_trigrams]\n",
    "brown_trigram_pos_tags_freq = nltk.FreqDist(brown_trigram_pos_tags)\n",
    "\n",
    "print(brown_trigram_pos_tags_freq[('JJ', 'NN', 'IN')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = nltk.corpus.brown.tagged_sents()\n",
    "\n",
    "total_size = len(brown_tagged_sents)\n",
    "train_size = int(total_size * 0.8)\n",
    "\n",
    "train_sents = brown_tagged_sents[:train_size]\n",
    "test_sents  = brown_tagged_sents[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8773754310202373\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = nltk.corpus.brown.tagged_sents()\n",
    "\n",
    "total_size = len(brown_tagged_sents)\n",
    "train_size = int(total_size * 0.8)\n",
    "\n",
    "train_sents = brown_tagged_sents[:train_size]\n",
    "test_sents  = brown_tagged_sents[train_size:]\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "tag_performace = unigram_tagger.evaluate(test_sents)\n",
    "\n",
    "print(tag_performace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'NNP'), ('is', 'VBZ'), ('awesome', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "s = 'Python is awesome'\n",
    "print(nltk.pos_tag(nltk.word_tokenize(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
