{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'is'),\n",
       " ('is', 'an'),\n",
       " ('an', 'awesome'),\n",
       " ('awesome', 'language'),\n",
       " ('language', '.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams represent a set of two consecutive words appearing in a text\n",
    "import nltk\n",
    "s = 'Python is an awesome language.'\n",
    "tokens = nltk.word_tokenize(s)\n",
    "list(nltk.bigrams(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'is', 'cool'),\n",
       " ('is', 'cool', '!'),\n",
       " ('cool', '!', '!'),\n",
       " ('!', '!', '!')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "s = 'Python is cool!!!'\n",
    "tokens = nltk.word_tokenize(s)\n",
    "list(nltk.trigrams(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import genesis\n",
    "eng_tokens = genesis.words('english-kjv.txt')\n",
    "eng_bigrams = nltk.bigrams(eng_tokens)\n",
    "filtered_bigrams = [ (w1, w2) for w1, w2 in eng_bigrams if len(w1) >=5 and len(w2) >= 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('their', 'father'), 19), (('lived', 'after'), 16), (('seven', 'years'), 15)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_bifreq = nltk.FreqDist(filtered_bigrams)\n",
    "eng_bifreq.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'earth',\n",
       " '.',\n",
       " 'And',\n",
       " 'was',\n",
       " 'without',\n",
       " 'form',\n",
       " ',',\n",
       " 'void',\n",
       " ';',\n",
       " 'darkness',\n",
       " 'upon',\n",
       " 'face',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'Spirit',\n",
       " 'moved',\n",
       " 'waters',\n",
       " 'said',\n",
       " 'Let',\n",
       " 'there',\n",
       " 'be',\n",
       " 'light',\n",
       " ':',\n",
       " 'saw',\n",
       " 'that',\n",
       " 'it',\n",
       " 'good',\n",
       " 'divided',\n",
       " 'from',\n",
       " 'called',\n",
       " 'Day',\n",
       " 'he',\n",
       " 'Night',\n",
       " 'evening',\n",
       " 'morning',\n",
       " 'were',\n",
       " 'first',\n",
       " 'day',\n",
       " 'a',\n",
       " 'firmament',\n",
       " 'in',\n",
       " 'midst',\n",
       " 'let',\n",
       " 'divide',\n",
       " 'made',\n",
       " 'which',\n",
       " 'under',\n",
       " 'above',\n",
       " 'firmame',\n",
       " 'so',\n",
       " 'Heaven',\n",
       " 'second',\n",
       " 'gathered',\n",
       " 'together',\n",
       " 'unto',\n",
       " 'one',\n",
       " 'place',\n",
       " 'dry',\n",
       " 'land',\n",
       " 'appe',\n",
       " 'Earth',\n",
       " 'gathering',\n",
       " 'Se',\n",
       " 'bring',\n",
       " 'forth',\n",
       " 'grass',\n",
       " 'herb',\n",
       " 'yielding',\n",
       " 'seed',\n",
       " 'fruit',\n",
       " 'tree',\n",
       " 'after',\n",
       " 'his',\n",
       " 'kind',\n",
       " 'whose',\n",
       " 'is',\n",
       " 'itself',\n",
       " 'ear',\n",
       " 'brought',\n",
       " 'ki',\n",
       " 'third',\n",
       " 'lights',\n",
       " 'to',\n",
       " 'night',\n",
       " 'them',\n",
       " 'for',\n",
       " 'signs',\n",
       " 'seasons',\n",
       " 'days',\n",
       " 'yea',\n",
       " 'give',\n",
       " 'two',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'rule',\n",
       " 'lesser',\n",
       " 'nig',\n",
       " 'stars',\n",
       " 'also',\n",
       " 'set',\n",
       " 'over',\n",
       " 'darkne',\n",
       " 'fourth',\n",
       " 'abundantly',\n",
       " 'moving',\n",
       " 'creature',\n",
       " 'hath',\n",
       " 'life',\n",
       " 'fowl',\n",
       " 'may',\n",
       " 'fly',\n",
       " 'open',\n",
       " 'whales',\n",
       " 'every',\n",
       " 'living',\n",
       " 'moveth',\n",
       " 'their',\n",
       " 'winged',\n",
       " 'blessed',\n",
       " 'saying',\n",
       " 'Be',\n",
       " 'fruitful',\n",
       " 'multiply',\n",
       " 'fill',\n",
       " 'seas',\n",
       " 'fifth',\n",
       " 'cattle',\n",
       " 'creeping',\n",
       " 'thing',\n",
       " 'beast',\n",
       " 'creepeth',\n",
       " 'us',\n",
       " 'make',\n",
       " 'man',\n",
       " 'our',\n",
       " 'image',\n",
       " 'likene',\n",
       " 'have',\n",
       " 'dominion',\n",
       " 'fish',\n",
       " 'sea',\n",
       " 'air',\n",
       " 'all',\n",
       " 'So',\n",
       " 'own',\n",
       " 'him',\n",
       " 'male',\n",
       " 'female',\n",
       " 'replenish',\n",
       " 'subdue',\n",
       " 'Behold',\n",
       " 'I',\n",
       " 'given',\n",
       " 'you',\n",
       " 'bearing',\n",
       " 'shall',\n",
       " 'meat',\n",
       " 'wherein',\n",
       " 'green',\n",
       " 'me',\n",
       " 'had',\n",
       " 'behold',\n",
       " 'very',\n",
       " 'sixth',\n",
       " 'Thus',\n",
       " 'heavens',\n",
       " 'finished',\n",
       " 'host',\n",
       " 'on',\n",
       " 'seventh',\n",
       " 'ended',\n",
       " 'work',\n",
       " 'rested',\n",
       " 'sanctified',\n",
       " 'because',\n",
       " 'These',\n",
       " 'are',\n",
       " 'generations',\n",
       " 'when',\n",
       " 'they',\n",
       " 'LORD',\n",
       " 'plant',\n",
       " 'field',\n",
       " 'before',\n",
       " 'gr',\n",
       " 'not',\n",
       " 'caused',\n",
       " 'rain',\n",
       " 'till',\n",
       " 'ground',\n",
       " 'But',\n",
       " 'went',\n",
       " 'up',\n",
       " 'mist',\n",
       " 'watered',\n",
       " 'whole',\n",
       " 'formed',\n",
       " 'dust',\n",
       " 'breathed',\n",
       " 'into',\n",
       " 'nostrils',\n",
       " 'breath',\n",
       " 'became',\n",
       " 'soul',\n",
       " 'planted',\n",
       " 'garden',\n",
       " 'eastward',\n",
       " 'Eden',\n",
       " 'put',\n",
       " 'whom',\n",
       " 'out',\n",
       " 'grow',\n",
       " 'pleasant',\n",
       " 'sight',\n",
       " 'food',\n",
       " 'knowledge',\n",
       " 'evil',\n",
       " 'river',\n",
       " 'water',\n",
       " 'thence',\n",
       " 'parted',\n",
       " 'four',\n",
       " 'heads',\n",
       " 'The',\n",
       " 'name',\n",
       " 'Pison',\n",
       " 'compasseth',\n",
       " 'Havilah',\n",
       " 'where',\n",
       " 'gold',\n",
       " 'bdellium',\n",
       " 'onyx',\n",
       " 'stone',\n",
       " 'Gihon',\n",
       " 'same',\n",
       " 'Ethiopia',\n",
       " 'Hiddekel',\n",
       " 'goeth',\n",
       " 'toward',\n",
       " 'east',\n",
       " 'Assyria',\n",
       " 'Euphrates',\n",
       " 'took',\n",
       " 'dress',\n",
       " 'keep',\n",
       " 'commanded',\n",
       " 'Of',\n",
       " 'thou',\n",
       " 'mayest',\n",
       " 'freely',\n",
       " 'e',\n",
       " 'shalt',\n",
       " 'eat',\n",
       " 'eatest',\n",
       " 'thereof',\n",
       " 'surely',\n",
       " 'die',\n",
       " 'It',\n",
       " 'should',\n",
       " 'alone',\n",
       " 'will',\n",
       " 'an',\n",
       " 'help',\n",
       " 'meet',\n",
       " 'Adam',\n",
       " 'see',\n",
       " 'what',\n",
       " 'would',\n",
       " 'call',\n",
       " 'th',\n",
       " 'whatsoever',\n",
       " 'gave',\n",
       " 'names',\n",
       " 'but',\n",
       " 'found',\n",
       " 'sleep',\n",
       " 'fall',\n",
       " 'sle',\n",
       " 'ribs',\n",
       " 'closed',\n",
       " 'flesh',\n",
       " 'instead',\n",
       " 'rib',\n",
       " 'taken',\n",
       " 'woman',\n",
       " 'her',\n",
       " 'This',\n",
       " 'now',\n",
       " 'bone',\n",
       " 'my',\n",
       " 'bones',\n",
       " 'fle',\n",
       " 'she',\n",
       " 'Woman',\n",
       " 'Man',\n",
       " 'Therefore',\n",
       " 'leave',\n",
       " 'father',\n",
       " 'mother',\n",
       " 'cleave',\n",
       " 'wife',\n",
       " 'both',\n",
       " 'naked',\n",
       " 'ashamed',\n",
       " 'Now',\n",
       " 'serpent',\n",
       " 'more',\n",
       " 'subtil',\n",
       " 'than',\n",
       " 'any',\n",
       " 'Yea',\n",
       " 'Ye',\n",
       " '?',\n",
       " 'We',\n",
       " 'trees',\n",
       " 'gard',\n",
       " 'neither',\n",
       " 'ye',\n",
       " 'touch',\n",
       " 'lest',\n",
       " 'For',\n",
       " 'doth',\n",
       " 'know',\n",
       " 'then',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'opened',\n",
       " 'as',\n",
       " 'gods',\n",
       " 'knowing',\n",
       " 'desired',\n",
       " 'wise',\n",
       " 'did',\n",
       " 'husband',\n",
       " 'with',\n",
       " 'knew',\n",
       " 'sewed',\n",
       " 'fig',\n",
       " 'leaves',\n",
       " 'themselves',\n",
       " 'aprons',\n",
       " 'heard',\n",
       " 'voice',\n",
       " 'walking',\n",
       " 'cool',\n",
       " 'd',\n",
       " 'hid',\n",
       " 'presence',\n",
       " 'amongst',\n",
       " 'Where',\n",
       " 'art',\n",
       " 'thy',\n",
       " 'afraid',\n",
       " 'myself',\n",
       " 'Who',\n",
       " 'told',\n",
       " 'thee',\n",
       " 'wast',\n",
       " 'Hast',\n",
       " 'eaten',\n",
       " 'whereof',\n",
       " 'shouldest',\n",
       " 'gavest',\n",
       " 'What',\n",
       " 'this',\n",
       " 'hast',\n",
       " 'done',\n",
       " 'beguiled',\n",
       " 'Because',\n",
       " 'cursed',\n",
       " 'belly',\n",
       " 'go',\n",
       " 'li',\n",
       " 'enmity',\n",
       " 'between',\n",
       " 'bruise',\n",
       " 'head',\n",
       " 'heel',\n",
       " 'Unto',\n",
       " 'greatly',\n",
       " 'sorrow',\n",
       " 'conception',\n",
       " 'children',\n",
       " 'desire',\n",
       " 'hearkened',\n",
       " 'Thou',\n",
       " 'sake',\n",
       " 'Thorns',\n",
       " 'thistles',\n",
       " 'sweat',\n",
       " 'bread',\n",
       " 'return',\n",
       " 'tak',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Eve',\n",
       " 'coats',\n",
       " 'skins',\n",
       " 'clothed',\n",
       " 'become',\n",
       " 'ev',\n",
       " 'hand',\n",
       " 'take',\n",
       " 'live',\n",
       " 'sent',\n",
       " 'whence',\n",
       " 'drove',\n",
       " 'placed',\n",
       " 'at',\n",
       " 'Cherubims',\n",
       " 'flaming',\n",
       " 'sword',\n",
       " 'turned',\n",
       " 'way',\n",
       " 'conceived',\n",
       " 'bare',\n",
       " 'Cain',\n",
       " 'gotten',\n",
       " 'again',\n",
       " 'brother',\n",
       " 'Abel',\n",
       " 'keeper',\n",
       " 'sheep',\n",
       " 'tiller',\n",
       " 'process',\n",
       " 'time',\n",
       " 'came',\n",
       " 'pass',\n",
       " 'offering',\n",
       " 'firstlings',\n",
       " 'flock',\n",
       " 'fat',\n",
       " 'respect',\n",
       " 'offeri',\n",
       " 'wroth',\n",
       " 'countenance',\n",
       " 'fell',\n",
       " 'Why',\n",
       " 'why',\n",
       " 'fallen',\n",
       " 'If',\n",
       " 'doest',\n",
       " 'well',\n",
       " 'accepted',\n",
       " 'if',\n",
       " 'sin',\n",
       " 'lieth',\n",
       " 'door',\n",
       " 'talked',\n",
       " 'rose',\n",
       " 'against',\n",
       " 'slew',\n",
       " 'n',\n",
       " 'Am',\n",
       " 'blood',\n",
       " 'crieth',\n",
       " 'mouth',\n",
       " 'receive',\n",
       " 'When',\n",
       " 'tillest',\n",
       " 'henceforth',\n",
       " 'yield',\n",
       " 'strength',\n",
       " 'fugitive',\n",
       " 'vagabond',\n",
       " 'My',\n",
       " 'punishment',\n",
       " 'can',\n",
       " 'bear',\n",
       " 'driven',\n",
       " 'come',\n",
       " 'findeth',\n",
       " 'slay',\n",
       " 'whosoever',\n",
       " 'slayeth',\n",
       " 'vengeance',\n",
       " 'sevenfold',\n",
       " 'mark',\n",
       " 'finding',\n",
       " 'kill',\n",
       " 'dwelt',\n",
       " 'Nod',\n",
       " 'Enoch',\n",
       " 'builded',\n",
       " 'city',\n",
       " 'son',\n",
       " 'born',\n",
       " 'Irad',\n",
       " 'begat',\n",
       " 'Mehujael',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Lamech',\n",
       " 'wives',\n",
       " 'Adah',\n",
       " 'other',\n",
       " 'Zillah',\n",
       " 'Jabal',\n",
       " 'such',\n",
       " 'dwell',\n",
       " 'tents',\n",
       " 'Jubal',\n",
       " 'handle',\n",
       " 'harp',\n",
       " 'organ',\n",
       " 'Tubalcain',\n",
       " 'instructor',\n",
       " 'artificer',\n",
       " 'brass',\n",
       " 'ir',\n",
       " 'sister',\n",
       " 'Naamah',\n",
       " 'Hear',\n",
       " 'hearken',\n",
       " 'spee',\n",
       " 'slain',\n",
       " 'wounding',\n",
       " 'young',\n",
       " 'hurt',\n",
       " 'avenged',\n",
       " 'truly',\n",
       " 'seventy',\n",
       " 'appointed',\n",
       " 'another',\n",
       " 'Seth',\n",
       " 'En',\n",
       " 'began',\n",
       " 'men',\n",
       " 'book',\n",
       " 'likeness',\n",
       " 'Male',\n",
       " 'lived',\n",
       " 'hundred',\n",
       " 'thirty',\n",
       " 'years',\n",
       " 'begotten',\n",
       " 'eight',\n",
       " 'sons',\n",
       " 'daughters',\n",
       " 'nine',\n",
       " 'died',\n",
       " 'five',\n",
       " 'Enos',\n",
       " 'seven',\n",
       " 'daughte',\n",
       " 'twelve',\n",
       " 'ninety',\n",
       " 'Cainan',\n",
       " 'fifteen',\n",
       " 'Mahalaleel',\n",
       " 'forty',\n",
       " 'ten',\n",
       " 'sixty',\n",
       " 'Jared',\n",
       " 'Eno',\n",
       " 'Methuselah',\n",
       " 'walked',\n",
       " 'three',\n",
       " 'eighty',\n",
       " 'Noah',\n",
       " 'comfort',\n",
       " 'concerning',\n",
       " 'toil',\n",
       " 'hands',\n",
       " 'old',\n",
       " 'Shem',\n",
       " 'Ham',\n",
       " 'Japheth',\n",
       " 'That',\n",
       " 'fair',\n",
       " 'chose',\n",
       " 'spirit',\n",
       " 'always',\n",
       " 'strive',\n",
       " 'yet',\n",
       " 'twenty',\n",
       " 'There',\n",
       " 'giants',\n",
       " 'those',\n",
       " 'mighty',\n",
       " 'renown',\n",
       " 'wickedness',\n",
       " 'imagination',\n",
       " 'thoughts',\n",
       " 'heart',\n",
       " 'only',\n",
       " 'continually',\n",
       " 'repented',\n",
       " 'grieved',\n",
       " 'destroy',\n",
       " 'fowls',\n",
       " 'repenteth',\n",
       " 'grace',\n",
       " 'just',\n",
       " 'perfect',\n",
       " 'corrupt',\n",
       " 'filled',\n",
       " 'violence',\n",
       " 'looked',\n",
       " 'corrupted',\n",
       " 'end',\n",
       " 'through',\n",
       " 'Make',\n",
       " 'ark',\n",
       " 'gopher',\n",
       " 'wood',\n",
       " 'rooms',\n",
       " 'pitch',\n",
       " 'within',\n",
       " 'fashion',\n",
       " 'length',\n",
       " 'cubits',\n",
       " 'breadth',\n",
       " 'fifty',\n",
       " 'height',\n",
       " 'A',\n",
       " 'window',\n",
       " 'cubit',\n",
       " 'finish',\n",
       " 'side',\n",
       " 'lower',\n",
       " 'stories',\n",
       " 'even',\n",
       " 'do',\n",
       " 'flood',\n",
       " 'establish',\n",
       " 'covenant',\n",
       " 'sort',\n",
       " 'alive',\n",
       " 'gather',\n",
       " 'according',\n",
       " 'Come',\n",
       " 'house',\n",
       " 'seen',\n",
       " 'righteous',\n",
       " 'generation',\n",
       " 'clean',\n",
       " 'by',\n",
       " 'sevens',\n",
       " 'fema',\n",
       " 'beasts',\n",
       " 'cause',\n",
       " 'nights',\n",
       " 'substance',\n",
       " 'off',\n",
       " 'six',\n",
       " 'hundredth',\n",
       " 'year',\n",
       " 'month',\n",
       " 'seventeenth',\n",
       " 'fountains',\n",
       " 'broken',\n",
       " 'windows',\n",
       " 'selfsame',\n",
       " 'entered',\n",
       " 'They',\n",
       " 'bird',\n",
       " 'h',\n",
       " 'shut',\n",
       " 'increased',\n",
       " 'lift',\n",
       " 'prevailed',\n",
       " 'exceedingly',\n",
       " 'high',\n",
       " 'hills',\n",
       " 'covered',\n",
       " 'Fifteen',\n",
       " 'upward',\n",
       " 'prevail',\n",
       " 'mountains',\n",
       " 'm',\n",
       " 'All',\n",
       " 'destroyed',\n",
       " 'things',\n",
       " 'remained',\n",
       " 'remembered',\n",
       " 'wind',\n",
       " 'asswaged',\n",
       " 'stopped',\n",
       " 'restrained',\n",
       " 'returned',\n",
       " 'abated',\n",
       " 'Ararat',\n",
       " 'decreased',\n",
       " 'until',\n",
       " 'tenth',\n",
       " 'tops',\n",
       " 'ma',\n",
       " 'raven',\n",
       " 'fro',\n",
       " 'dried',\n",
       " 'Also',\n",
       " 'dove',\n",
       " 'no',\n",
       " 'rest',\n",
       " 'sole',\n",
       " 'foot',\n",
       " 'pulled',\n",
       " 'stayed',\n",
       " 'lo',\n",
       " 'olive',\n",
       " 'leaf',\n",
       " 'pluckt',\n",
       " 'o',\n",
       " 'removed',\n",
       " 'covering',\n",
       " 'twentieth',\n",
       " 'spake',\n",
       " 'Go',\n",
       " 'Bring',\n",
       " 'breed',\n",
       " 'Every',\n",
       " 'kinds',\n",
       " 'altar',\n",
       " 'offered',\n",
       " 'burnt',\n",
       " 'offerings',\n",
       " 'smelled',\n",
       " 'sweet',\n",
       " 'savour',\n",
       " 'curse',\n",
       " 'youth',\n",
       " 'smite',\n",
       " 'While',\n",
       " 'remaineth',\n",
       " 'seedtime',\n",
       " 'harvest',\n",
       " 'cold',\n",
       " 'heat',\n",
       " 'summer',\n",
       " 'winter',\n",
       " 'cease',\n",
       " 'fear',\n",
       " 'dread',\n",
       " 'fishes',\n",
       " 'delivered',\n",
       " 'liveth',\n",
       " 'lives',\n",
       " 'require',\n",
       " 'Whoso',\n",
       " 'sheddeth',\n",
       " 'shed',\n",
       " 'therein',\n",
       " 'cut',\n",
       " 'token',\n",
       " 'perpetual',\n",
       " 'generatio',\n",
       " 'bow',\n",
       " 'cloud',\n",
       " 'clo',\n",
       " 'remember',\n",
       " 'look',\n",
       " 'everlasting',\n",
       " 'established',\n",
       " 'Japhe',\n",
       " 'Canaan',\n",
       " 'overspread',\n",
       " 'husbandman',\n",
       " 'vineyard',\n",
       " 'drank',\n",
       " 'wine',\n",
       " 'drunken',\n",
       " 'uncovered',\n",
       " 'tent',\n",
       " 'nakedness',\n",
       " 'brethren',\n",
       " 'garment',\n",
       " 'laid',\n",
       " 'shoulders',\n",
       " 'backward',\n",
       " 'faces',\n",
       " 'awoke',\n",
       " 'younger',\n",
       " 'Cursed',\n",
       " 'servant',\n",
       " 'servants',\n",
       " 'Blessed',\n",
       " 'enlarge',\n",
       " 'these',\n",
       " 'Gomer',\n",
       " 'Magog',\n",
       " 'Madai',\n",
       " 'Javan',\n",
       " 'Tubal',\n",
       " 'Meshech',\n",
       " 'Tiras',\n",
       " 'Ashkenaz',\n",
       " 'Riphath',\n",
       " 'Togarmah',\n",
       " 'Elishah',\n",
       " 'Tarshish',\n",
       " 'Kittim',\n",
       " 'Dodanim',\n",
       " 'By',\n",
       " 'isles',\n",
       " 'Gentiles',\n",
       " 'lands',\n",
       " 'tongue',\n",
       " 'families',\n",
       " 'nations',\n",
       " 'Cush',\n",
       " 'Mizraim',\n",
       " 'Phut',\n",
       " 'Seba',\n",
       " 'Sabtah',\n",
       " 'Raamah',\n",
       " 'Sabtech',\n",
       " 'Sheba',\n",
       " 'Dedan',\n",
       " 'Nimrod',\n",
       " 'He',\n",
       " 'hunter',\n",
       " 'wherefore',\n",
       " 'Even',\n",
       " 'kingdom',\n",
       " 'Babel',\n",
       " 'Erech',\n",
       " 'Accad',\n",
       " 'Calneh',\n",
       " 'Shinar',\n",
       " 'Out',\n",
       " 'Asshur',\n",
       " 'Nineveh',\n",
       " 'Rehoboth',\n",
       " 'Calah',\n",
       " 'Resen',\n",
       " 'Ludim',\n",
       " 'Anamim',\n",
       " 'Lehabim',\n",
       " 'Naphtuhim',\n",
       " 'Pathrusim',\n",
       " 'Casluhim',\n",
       " '(',\n",
       " 'Philistim',\n",
       " ',)',\n",
       " 'Caphtorim',\n",
       " 'Sidon',\n",
       " 'Heth',\n",
       " 'Jebusite',\n",
       " 'Amorite',\n",
       " 'Girgasite',\n",
       " 'Hivite',\n",
       " 'Arkite',\n",
       " 'Sinite',\n",
       " 'Arvadite',\n",
       " 'Zemarite',\n",
       " 'Hamathite',\n",
       " 'afterward',\n",
       " 'Canaanites',\n",
       " 'spread',\n",
       " 'abroad',\n",
       " 'border',\n",
       " 'comest',\n",
       " 'Gerar',\n",
       " 'Gaza',\n",
       " 'goest',\n",
       " 'Sodom',\n",
       " 'Gomorrah',\n",
       " 'Admah',\n",
       " 'Zeboim',\n",
       " 'Lasha',\n",
       " 'tongues',\n",
       " 'countries',\n",
       " 'Eber',\n",
       " 'elder',\n",
       " 'Elam',\n",
       " 'Arphaxad',\n",
       " 'Lud',\n",
       " 'Aram',\n",
       " 'Uz',\n",
       " 'Hul',\n",
       " 'Gether',\n",
       " 'Mash',\n",
       " 'Salah',\n",
       " 'Peleg',\n",
       " 'Joktan',\n",
       " 'Almodad',\n",
       " 'Sheleph',\n",
       " 'Hazarmaveth',\n",
       " 'Jerah',\n",
       " 'Hadoram',\n",
       " 'Uzal',\n",
       " 'Diklah',\n",
       " 'Obal',\n",
       " 'Abimael',\n",
       " 'Ophir',\n",
       " 'Jobab',\n",
       " 'dwelling',\n",
       " 'Mesha',\n",
       " 'Sephar',\n",
       " 'mount',\n",
       " 'natio',\n",
       " 'language',\n",
       " 'speech',\n",
       " 'journeyed',\n",
       " 'plain',\n",
       " 'brick',\n",
       " 'burn',\n",
       " 'thoroughly',\n",
       " 'slime',\n",
       " 'morter',\n",
       " 'build',\n",
       " 'tower',\n",
       " 'top',\n",
       " 'reach',\n",
       " 'we',\n",
       " 'scattered',\n",
       " 'down',\n",
       " 'people',\n",
       " 'begin',\n",
       " 'nothing',\n",
       " 'imagined',\n",
       " 'confound',\n",
       " 'understand',\n",
       " 'left',\n",
       " 'scatter',\n",
       " 'flo',\n",
       " 'Reu',\n",
       " 'Serug',\n",
       " 'Nahor',\n",
       " 'Terah',\n",
       " 'nineteen',\n",
       " 'Abram',\n",
       " 'Haran',\n",
       " 'Lot',\n",
       " 'nativity',\n",
       " 'Ur',\n",
       " 'Chaldees',\n",
       " 'Sarai',\n",
       " 'Milcah',\n",
       " 'daughter',\n",
       " 'Iscah',\n",
       " 'barren',\n",
       " 'child',\n",
       " 'law',\n",
       " 'Get',\n",
       " 'country',\n",
       " 'kindred',\n",
       " 'shew',\n",
       " 'nation',\n",
       " 'bless',\n",
       " 'blessi',\n",
       " 'curseth',\n",
       " 'departed',\n",
       " 'spoken',\n",
       " 'souls',\n",
       " 'passed',\n",
       " 'Sichem',\n",
       " 'Moreh',\n",
       " 'Canaanite',\n",
       " 'appeared',\n",
       " 'la',\n",
       " 'who',\n",
       " 'mountain',\n",
       " 'Bethel',\n",
       " 'pitched',\n",
       " 'having',\n",
       " 'west',\n",
       " 'Hai',\n",
       " 'ea',\n",
       " 'going',\n",
       " 'still',\n",
       " 'south',\n",
       " 'famine',\n",
       " 'Egypt',\n",
       " 'sojourn',\n",
       " 'grievous',\n",
       " 'near',\n",
       " 'enter',\n",
       " 'Egyptians',\n",
       " 'say',\n",
       " 'save',\n",
       " 'Say',\n",
       " 'pray',\n",
       " 'beheld',\n",
       " 'princes',\n",
       " 'Pharaoh',\n",
       " 'commended',\n",
       " 'Phara',\n",
       " 'entreated',\n",
       " 'oxen',\n",
       " 'asses',\n",
       " 'menservants',\n",
       " 'maidservants',\n",
       " 'camels',\n",
       " 'plagued',\n",
       " 'plagues',\n",
       " 'didst',\n",
       " 'tell',\n",
       " 'saidst',\n",
       " 'She',\n",
       " 'might',\n",
       " 'therefore',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import genesis\n",
    "eng_tokens = genesis.words('english-kjv.txt')\n",
    "eng_bigrams = nltk.bigrams(eng_tokens)\n",
    "eng_cfd = nltk.ConditionalFreqDist(eng_bigrams)\n",
    "eng_cfd.conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('creature', 7), ('thing', 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import genesis\n",
    "eng_tokens = genesis.words('english-kjv.txt')\n",
    "eng_bigrams = nltk.bigrams(eng_tokens)\n",
    "eng_cfd = nltk.ConditionalFreqDist(eng_bigrams)\n",
    "eng_cfd['living'].most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(cfd, word, n=5):\n",
    "    n_words = []\n",
    "    for i in range(n):\n",
    "        n_words.append(word)\n",
    "        word = cfd[word].max()\n",
    "        return n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['living']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(eng_cfd, 'living')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'is', 'an'),\n",
       " ('is', 'an', 'awesome'),\n",
       " ('an', 'awesome', 'language'),\n",
       " ('awesome', 'language', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Python is an awesome language.'\n",
    "tokens = nltk.word_tokenize(s)\n",
    "list(nltk.trigrams(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'is', 'an', 'awesome'),\n",
       " ('is', 'an', 'awesome', 'language'),\n",
       " ('an', 'awesome', 'language', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(tokens, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'is', 'an'),\n",
       " ('is', 'an', 'awesome'),\n",
       " ('an', 'awesome', 'language'),\n",
       " ('awesome', 'language', '.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said unto; pray thee; thou shalt; thou hast; thy seed; years old;\n",
      "spake unto; thou art; LORD God; every living; God hath; begat sons;\n",
      "seven years; shalt thou; little ones; living creature; creeping thing;\n",
      "savoury meat; thirty years; every beast\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import genesis\n",
    "tokens = genesis.words('english-kjv.txt')\n",
    "gen_text = nltk.Text(tokens)\n",
    "gen_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   19   20 \n",
      "6 1535 1746 1232 1032  608  567  481  340  248  145   87   48   28   22    1    2    1    1    0 \n",
      "4 2123 2768 2322 2096 1256 1084  916  609  478  282  113   60   33   16    5    1    1    0    1 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "news_words     = brown.words(categories='news')\n",
    "lc_news_words  = [w.lower() for w in news_words]\n",
    "len_news_words = [len(w) for w in lc_news_words]\n",
    "news_len_bigrams = list(nltk.bigrams(len_news_words))\n",
    "#Compute the conditional frequency of news_len_bigrams, where condition and event refers to length of a words. \n",
    "#Store the result in cfd_news\n",
    "#Determine the frequency of 6-letter words appearing next to a 4-letter word\n",
    "cfd_news = nltk.ConditionalFreqDist(news_len_bigrams)\n",
    "cfd_news.tabulate(conditions=[6,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084\n"
     ]
    }
   ],
   "source": [
    "#Promblem 1\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "news_words = brown.words(categories='news')\n",
    "lc_news_words = map(lambda x:x.lower(),news_words)\n",
    "len_news_words = map(lambda x:len(x),news_words)\n",
    "news_len_bigrams = list(nltk.bigrams(len_news_words))\n",
    "\n",
    "cfd_news = nltk.ConditionalFreqDist(news_len_bigrams)\n",
    "\n",
    "print([(i,j) for i,j in cfd_news[4].most_common(25) if i == 6][0][1])\n",
    "lc_news_words = map(lambda x:x.lower(),news_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2\n",
    "#Bigrams of News Words\n",
    "lc_news_bigrams = list(nltk.bigrams(lc_news_words))\n",
    "#Filtered BiGrams\n",
    "lc_news_alpha_bigrams = [ (w1, w2) for w1, w2 in lc_news_bigrams if w1.isalpha()==True and w2.isalpha()==True]\n",
    "from nltk.corpus import stopwords\n",
    "#Stopwords\n",
    "stop_words = stopwords.words()\n",
    "lc_stop_words = [w.lower() for w in stop_words]\n",
    "#List of Bigrams not part of Stop Words\n",
    "lc_news_alpha_nonstop_bigrams = [(w1, w2) for w1, w2 in lc_news_alpha_bigrams if not w1 in lc_stop_words and not w2 in lc_stop_words]\n",
    "#Total Number of Bigrams\n",
    "print(len(lc_news_alpha_bigrams) + len(lc_news_alpha_nonstop_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87269\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "news_words     = brown.words(categories='news')\n",
    "lc_news_words  = [w.lower() for w in news_words]\n",
    "\n",
    "# Compute bigrams of the list lc_news_words, and store it in the variable lc_news_bigrams\n",
    "lc_news_bigrams = list(nltk.bigrams(lc_news_words))\n",
    "\n",
    "# From lc_news_bigrams, filter bigrams where both words contain only alphabet characters. \n",
    "# Store the result in lc_news_alpha_bigrams\n",
    "lc_news_alpha_bigrams = [ (w1, w2) for w1, w2 in lc_news_bigrams if w1.isalpha()==True and w2.isalpha()==True]\n",
    "\n",
    "# Extract the list of words associated with the corpus stopwords. Store the result in stop_words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words()\n",
    "\n",
    "# Convert each word of the list stop_words into lower case, and store the result in lc_stop_words\n",
    "lc_stop_words = [w.lower() for w in stop_words]\n",
    "\n",
    "# Filter only the bigrams from lc_news_alpha_bigrams where the words are not part of lc_stop_words. \n",
    "# Store the result in lc_news_alpha_nonstop_bigrams.\n",
    "lc_news_alpha_nonstop_bigrams = [(w1, w2) for w1, w2 in lc_news_alpha_bigrams \n",
    "                                 if not w1 in lc_stop_words and not w2 in lc_stop_words]\n",
    "\n",
    "# Print the total number of filtered bigrams\n",
    "print(len(lc_news_alpha_bigrams) + len(lc_news_alpha_nonstop_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('King', 'Arthur'), 16)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the frequency of bigram ('King', 'Arthur') in text collection text6\n",
    "import nltk\n",
    "from nltk.book import text6\n",
    "\n",
    "text6_word = [ word for word in text6 ]\n",
    "eng_bigrams = nltk.bigrams(text6_word)\n",
    "filtered_bigrams = [(w1, w2) for w1, w2 in eng_bigrams if w1 == 'King' and w2 == 'Arthur']\n",
    "eng_bifreq = nltk.FreqDist(filtered_bigrams)\n",
    "eng_bifreq.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('BLACK', 'KNIGHT'), 32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the frequency of bigram ('clop', 'clop') in text collection text6\n",
    "import nltk\n",
    "from nltk.book import text6\n",
    "\n",
    "text6_word = [ word for word in text6 ]\n",
    "eng_bigrams = nltk.bigrams(text6_word)\n",
    "filtered_bigrams = [(w1, w2) for w1, w2 in eng_bigrams if w1 == 'BLACK' and w2 == 'KNIGHT']\n",
    "eng_bifreq = nltk.FreqDist(filtered_bigrams)\n",
    "eng_bifreq.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GUARD', 21), ('GUARDS', 8)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which of the following word occurs frequently after the word Holy in text collection text6\n",
    "import nltk\n",
    "from nltk.book import text6\n",
    "\n",
    "text6_word = [ word for word in text6 ]\n",
    "eng_bigrams = nltk.bigrams(text6_word)\n",
    "\n",
    "eng_cfd = nltk.ConditionalFreqDist(eng_bigrams)\n",
    "eng_cfd['FRENCH'].most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLACK KNIGHT; clop clop; HEAD KNIGHT; mumble mumble; Holy Grail;\n",
      "squeak squeak; FRENCH GUARD; saw saw; Sir Robin; Run away; CARTOON\n",
      "CHARACTER; King Arthur; Iesu domine; Pie Iesu; DEAD PERSON; Round\n",
      "Table; clap clap; OLD MAN; dramatic chord; dona eis\n"
     ]
    }
   ],
   "source": [
    "# Which of the following is not a collocation, associated with text6\n",
    "import nltk\n",
    "from nltk.book import text6\n",
    "text6_word = [ word for word in text6 ]\n",
    "gen_text = nltk.Text(text6_word)\n",
    "gen_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      " \n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "15\n",
      " \n",
      "1161192\n",
      " \n",
      "100554\n",
      " \n",
      "100554\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "print(len(brown.fileids()))\n",
    "print(' ')\n",
    "\n",
    "cat = brown.categories()\n",
    "print(cat)\n",
    "print(len(cat))\n",
    "print(' ')\n",
    "\n",
    "all_words      = brown.words()\n",
    "print(len(all_words))\n",
    "print(' ')\n",
    "\n",
    "news_words     = brown.words(categories='news')\n",
    "print(len(news_words))\n",
    "print(' ')\n",
    "\n",
    "lc_news_words  = [w.lower() for w in news_words]\n",
    "\n",
    "len_news_words = [len(w) for w in lc_news_words]\n",
    "print(len(len_news_words))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "news_words     = brown.words(categories='news')\n",
    "lc_news_words  = [w.lower() for w in news_words]\n",
    "len_news_words = [len(w) for w in lc_news_words]\n",
    "news_len_bigrams = list(nltk.bigrams(len_news_words))\n",
    "#Compute the conditional frequency of news_len_bigrams, where condition and event refers to length of a words. \n",
    "#Store the result in cfd_news\n",
    "#Determine the frequency of 6-letter words appearing next to a 4-letter word\n",
    "cfd_news = nltk.ConditionalFreqDist(news_len_bigrams)\n",
    "cfd_news.tabulate(conditions=[6,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
